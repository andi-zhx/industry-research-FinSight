# memory_system/memory_manager.py

import datetime
from ingestion.pdf_ingest import PDFIngestor
from memory_system.vector_store.chroma_client import ChromaVectorStore
from rag.retriever import VectorRetriever
from langchain.text_splitter import RecursiveCharacterTextSplitter

class MemoryManager:
    """
    å…¨ç»´æŠ•ç ”è®°å¿†ç³»ç»Ÿ
    æ”¯æŒï¼šPDFåŸæ–‡ã€Agentäº§å‡ºçš„äº‹å®ã€è§‚ç‚¹ã€ç»“è®ºã€æ­£æ–‡æ®µè½
    """

    def __init__(self, persist_dir: str):
        self.vector_store = ChromaVectorStore(persist_dir)
        self.retriever = VectorRetriever(self.vector_store)
        self.pdf_ingestor = PDFIngestor()
        
        # ä¸åŒçš„å†…å®¹åˆ‡åˆ†ç­–ç•¥å¯èƒ½ä¸åŒï¼Œè¿™é‡Œæš‚ç”¨é€šç”¨ç­–ç•¥
        self.splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)

    # ------------------ å­˜å…¥ (Write) ------------------

    def save_insight(self, content: str, category: str, metadata: dict):
        """
        æ ¸å¿ƒæ–¹æ³•ï¼šå­˜å‚¨ Agent çš„äº§å‡º
        :param content: æ–‡æœ¬å†…å®¹
        :param category: 'fact' | 'opinion' | 'conclusion' | 'report_segment'
        :param metadata: {industry, year, province, focus, source_agent}
        """
        if not content: return

        # è‡ªåŠ¨è¡¥å…¨å…ƒæ•°æ®
        meta = metadata.copy()
        meta.update({
            "category": category,
            "ingest_time": datetime.datetime.now().isoformat(),
            "type": "agent_memory" # åŒºåˆ«äº pdf_file
        })

        # å­˜å…¥å‘é‡åº“
        # æ³¨æ„ï¼šå¦‚æœæ˜¯çŸ­ç»“è®ºï¼Œå¯ä»¥ä¸åˆ‡åˆ†ç›´æ¥å­˜ï¼›é•¿æ®µè½éœ€è¦åˆ‡åˆ†
        if len(content) < 500:
            chunks = [content]
        else:
            chunks = self.splitter.split_text(content)
            
        metadatas = [meta for _ in chunks]
        self.vector_store.add_texts(chunks, metadatas)
        print(f"ğŸ§  [Memory] å·²å­˜å‚¨ {len(chunks)} æ¡ {category} è®°å¿†")

    def ingest_pdf(self, file_path: str, metadata: dict):
        raw_text = self.pdf_ingestor.ingest(file_path)
        chunks = self.splitter.split_text(raw_text)
        metadatas = [metadata for _ in chunks]
        self.vector_store.add_texts(chunks, metadatas)

    # ------------------ å¬å› (Read) ------------------

    def recall_memory(self, query: str, category: str = None, k: int = 5):
        """
        ç²¾å‡†å¬å›ï¼šæ”¯æŒæŒ‰ category è¿‡æ»¤
        ä¾‹å¦‚ï¼šAnalyst åªæƒ³çœ‹ä¹‹å‰çš„ 'fact'ï¼ŒWriter æƒ³çœ‹ä¹‹å‰çš„ 'conclusion'
        """
        # æ³¨æ„ï¼šåº•å±‚ ChromaClient éœ€è¦æ”¯æŒ where è¿‡æ»¤
        # è¿™é‡Œå‡è®¾æ‚¨çš„ VectorRetriever æ”¯æŒ filter å‚æ•°ï¼Œå¦‚æœä¸æ”¯æŒéœ€ä¿®æ”¹åº•å±‚
        # ä¸´æ—¶æ–¹æ¡ˆï¼šå…ˆæ£€ç´¢å¤šä¸€ç‚¹ï¼Œå†åœ¨å†…å­˜é‡Œè¿‡æ»¤ (å¦‚æœåº•å±‚ä¸æ”¯æŒ metadata è¿‡æ»¤)
        results = self.retriever.retrieve(query, k=k * 2) 
        
        if category:
            # ç®€å•çš„å†…å­˜è¿‡æ»¤ç¤ºä¾‹ (å®é™…å»ºè®®ä¸‹æ¨åˆ°æ•°æ®åº“å±‚)
            # å‡è®¾ retrieve è¿”å›çš„æ˜¯ Document å¯¹è±¡æˆ–å¸¦ metadata çš„å­—å…¸
            # è¿™é‡Œéœ€è¦æ ¹æ®æ‚¨å®é™…çš„ retriever è¿”å›ç»“æ„è°ƒæ•´
            pass 
            
        return results

# å…¨å±€å•ä¾‹
memory_manager = MemoryManager(persist_dir="./knowledge_base/vector_store")


