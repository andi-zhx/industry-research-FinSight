# memory_system/enhanced_memory.py
"""
å¢å¼ºç‰ˆMemoryæ¨¡å—
é›†æˆäº‹å®æ ¸æŸ¥ã€å…¨å±€ä¸Šä¸‹æ–‡å…±äº«ã€æ™ºèƒ½å­¦ä¹ 

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. äº‹å®æ ¸æŸ¥ - å†™ä½œå‰æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
2. å…¨å±€ä¸Šä¸‹æ–‡ - ç¡®ä¿æ‰€æœ‰Agentå…±äº«ä¸€è‡´æ•°æ®
3. æ™ºèƒ½å­¦ä¹  - ä»æˆåŠŸç ”ç©¶ä¸­æå–ç»éªŒ
4. çŸ¥è¯†å›¾è°± - æ„å»ºè¡Œä¸šå…³è”ç½‘ç»œ
"""

import datetime
import json
import hashlib
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from collections import defaultdict

# å¯¼å…¥å…¨å±€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
from agent_system.context.global_context import (
    global_context_manager, 
    fact_checker,
    GlobalContext
)


@dataclass
class ResearchSession:
    """ç ”ç©¶ä¼šè¯"""
    session_id: str
    industry: str
    province: str
    target_year: str
    focus: str
    start_time: str
    status: str = "active"
    
    # ä¼šè¯æ•°æ®
    collected_facts: Dict[str, Any] = field(default_factory=dict)
    agent_outputs: Dict[str, str] = field(default_factory=dict)
    quality_scores: Dict[str, float] = field(default_factory=dict)
    
    # å…ƒæ•°æ®
    total_searches: int = 0
    total_rag_queries: int = 0
    data_coverage: float = 0.0


class EnhancedMemoryManager:
    """
    å¢å¼ºç‰ˆè®°å¿†ç®¡ç†å™¨
    æ•´åˆäº‹å®æ ¸æŸ¥ã€ä¸Šä¸‹æ–‡å…±äº«ã€æ™ºèƒ½å­¦ä¹ 
    """
    
    def __init__(self, base_memory_manager=None):
        """
        åˆå§‹åŒ–å¢å¼ºè®°å¿†ç®¡ç†å™¨
        
        Args:
            base_memory_manager: åŸºç¡€è®°å¿†ç®¡ç†å™¨å®ä¾‹
        """
        self.base_manager = base_memory_manager
        self.ctx_manager = global_context_manager
        self.fact_checker = fact_checker
        
        # å½“å‰ç ”ç©¶ä¼šè¯
        self.current_session: Optional[ResearchSession] = None
        
        # ä¼šè¯å†å²
        self.session_history: List[ResearchSession] = []
        
        # å­¦ä¹ è®°å½•
        self.learning_records: List[Dict] = []
    
    def start_session(self, industry: str, province: str, 
                      target_year: str, focus: str) -> ResearchSession:
        """
        å¼€å§‹æ–°çš„ç ”ç©¶ä¼šè¯
        
        Args:
            industry: è¡Œä¸š
            province: çœä»½
            target_year: ç›®æ ‡å¹´ä»½
            focus: ç ”ç©¶ä¾§é‡ç‚¹
        
        Returns:
            ResearchSession: æ–°çš„ä¼šè¯å¯¹è±¡
        """
        # ç”Ÿæˆä¼šè¯ID
        session_id = hashlib.md5(
            f"{industry}_{province}_{target_year}_{datetime.datetime.now().isoformat()}".encode()
        ).hexdigest()[:12]
        
        # åˆå§‹åŒ–å…¨å±€ä¸Šä¸‹æ–‡
        self.ctx_manager.init_context(industry, province, target_year, focus)
        
        # åˆ›å»ºä¼šè¯
        self.current_session = ResearchSession(
            session_id=session_id,
            industry=industry,
            province=province,
            target_year=target_year,
            focus=focus,
            start_time=datetime.datetime.now().isoformat()
        )
        
        print(f"ğŸš€ [EnhancedMemory] å¼€å§‹ç ”ç©¶ä¼šè¯: {session_id}")
        print(f"   è¡Œä¸š: {industry} | åŒºåŸŸ: {province} | å¹´ä»½: {target_year}")
        
        return self.current_session
    
    def register_fact(self, key: str, value: Any, source: str, 
                      agent: str = "") -> bool:
        """
        æ³¨å†Œäº‹å®åˆ°å…¨å±€ä¸Šä¸‹æ–‡
        
        Args:
            key: äº‹å®æ ‡è¯†
            value: äº‹å®å€¼
            source: æ•°æ®æ¥æº
            agent: è®°å½•çš„Agent
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ³¨å†Œ
        """
        success = self.ctx_manager.register_fact(key, value, source, agent)
        
        # åŒæ—¶è®°å½•åˆ°ä¼šè¯
        if self.current_session:
            self.current_session.collected_facts[key] = {
                "value": value,
                "source": source,
                "agent": agent,
                "timestamp": datetime.datetime.now().isoformat()
            }
        
        return success
    
    def check_consistency(self, content: str) -> Dict[str, Any]:
        """
        æ£€æŸ¥å†…å®¹çš„æ•°æ®ä¸€è‡´æ€§
        
        Args:
            content: å¾…æ£€æŸ¥çš„å†…å®¹
        
        Returns:
            Dict: æ£€æŸ¥ç»“æœ
        """
        return self.fact_checker.check_content(content)
    
    def get_context_prompt(self) -> str:
        """
        è·å–å…¨å±€ä¸Šä¸‹æ–‡çš„Promptæ ¼å¼
        ç”¨äºæ³¨å…¥åˆ°Agentæç¤ºè¯ä¸­
        """
        return self.ctx_manager.export_context_prompt()
    
    def record_agent_output(self, agent_name: str, output: str, 
                            quality_score: float = None):
        """
        è®°å½•Agentè¾“å‡º
        
        Args:
            agent_name: Agentåç§°
            output: è¾“å‡ºå†…å®¹
            quality_score: è´¨é‡è¯„åˆ†
        """
        if self.current_session:
            self.current_session.agent_outputs[agent_name] = output
            if quality_score is not None:
                self.current_session.quality_scores[agent_name] = quality_score
        
        # ä»è¾“å‡ºä¸­æå–äº‹å®
        self._extract_and_register_facts(output, agent_name)
    
    def _extract_and_register_facts(self, content: str, agent: str):
        """ä»å†…å®¹ä¸­æå–äº‹å®å¹¶æ³¨å†Œ"""
        import re
        
        # æå–å¸‚åœºè§„æ¨¡
        market_patterns = [
            r'å¸‚åœºè§„æ¨¡[ï¼š:çº¦ä¸ºè¾¾åˆ°]\s*([\d,\.]+)\s*(äº¿|ä¸‡)',
            r'è§„æ¨¡[ï¼š:çº¦ä¸ºè¾¾åˆ°]\s*([\d,\.]+)\s*(äº¿|ä¸‡)',
        ]
        for pattern in market_patterns:
            match = re.search(pattern, content)
            if match:
                value = float(match.group(1).replace(",", ""))
                unit = match.group(2)
                self.register_fact(
                    f"å¸‚åœºè§„æ¨¡_{self.ctx_manager.context.target_year}",
                    f"{value}{unit}å…ƒ",
                    f"Agent:{agent}æå–"
                )
                break
        
        # æå–å¢é•¿ç‡
        growth_patterns = [
            r'å¢[é•¿é€Ÿ][ç‡åº¦][ï¼š:çº¦ä¸ºè¾¾åˆ°]\s*([\d\.]+)\s*%',
            r'CAGR[ï¼š:çº¦ä¸ºè¾¾åˆ°]\s*([\d\.]+)\s*%',
        ]
        for pattern in growth_patterns:
            match = re.search(pattern, content)
            if match:
                value = float(match.group(1))
                self.register_fact(
                    "å¢é•¿ç‡",
                    f"{value}%",
                    f"Agent:{agent}æå–"
                )
                break
    
    def get_data_coverage(self) -> Dict[str, Any]:
        """
        è·å–æ•°æ®è¦†ç›–ç‡æŠ¥å‘Š
        """
        from agent_system.quality.data_quality import data_quality_checker
        
        if not self.current_session:
            return {"error": "æ— æ´»åŠ¨ä¼šè¯"}
        
        # åˆå¹¶æ‰€æœ‰Agentè¾“å‡º
        combined_content = "\n".join(self.current_session.agent_outputs.values())
        
        # æ£€æŸ¥è¦†ç›–ç‡
        quality = data_quality_checker.check_coverage(combined_content)
        
        # æ›´æ–°ä¼šè¯
        self.current_session.data_coverage = quality.total_score
        
        return {
            "total_score": quality.total_score,
            "dimension_scores": quality.dimension_scores,
            "missing_data": quality.missing_data,
            "pass_threshold": quality.pass_threshold,
            "recommendations": quality.recommendations
        }
    
    def end_session(self, final_report: str = None, 
                    quality_score: float = None) -> Dict[str, Any]:
        """
        ç»“æŸç ”ç©¶ä¼šè¯
        
        Args:
            final_report: æœ€ç»ˆæŠ¥å‘Š
            quality_score: æœ€ç»ˆè´¨é‡è¯„åˆ†
        
        Returns:
            Dict: ä¼šè¯æ€»ç»“
        """
        if not self.current_session:
            return {"error": "æ— æ´»åŠ¨ä¼šè¯"}
        
        self.current_session.status = "completed"
        
        # è®¡ç®—ä¼šè¯ç»Ÿè®¡
        summary = {
            "session_id": self.current_session.session_id,
            "industry": self.current_session.industry,
            "province": self.current_session.province,
            "duration": self._calculate_duration(),
            "facts_collected": len(self.current_session.collected_facts),
            "agents_involved": list(self.current_session.agent_outputs.keys()),
            "data_coverage": self.current_session.data_coverage,
            "quality_score": quality_score,
            "conflicts": len(self.ctx_manager.get_conflicts())
        }
        
        # å­¦ä¹ ç»éªŒ
        if quality_score and quality_score >= 0.8:
            self._learn_from_success()
        
        # ä¿å­˜åˆ°å†å²
        self.session_history.append(self.current_session)
        
        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Šåˆ°åŸºç¡€è®°å¿†
        if final_report and self.base_manager:
            self.base_manager.save_insight(
                content=final_report,
                category="report_segment",
                metadata={
                    "industry": self.current_session.industry,
                    "province": self.current_session.province,
                    "year": self.current_session.target_year,
                    "session_id": self.current_session.session_id,
                    "quality_score": quality_score
                }
            )
        
        print(f"âœ… [EnhancedMemory] ä¼šè¯ç»“æŸ: {self.current_session.session_id}")
        print(f"   æ”¶é›†äº‹å®: {summary['facts_collected']} | æ•°æ®è¦†ç›–ç‡: {summary['data_coverage']:.1%}")
        
        self.current_session = None
        
        return summary
    
    def _calculate_duration(self) -> str:
        """è®¡ç®—ä¼šè¯æŒç»­æ—¶é—´"""
        if not self.current_session:
            return "0åˆ†é’Ÿ"
        
        start = datetime.datetime.fromisoformat(self.current_session.start_time)
        duration = datetime.datetime.now() - start
        minutes = int(duration.total_seconds() / 60)
        
        if minutes < 60:
            return f"{minutes}åˆ†é’Ÿ"
        else:
            hours = minutes // 60
            mins = minutes % 60
            return f"{hours}å°æ—¶{mins}åˆ†é’Ÿ"
    
    def _learn_from_success(self):
        """ä»æˆåŠŸçš„ç ”ç©¶ä¸­å­¦ä¹ """
        if not self.current_session:
            return
        
        # æå–æˆåŠŸæ¨¡å¼
        pattern = {
            "industry": self.current_session.industry,
            "province": self.current_session.province,
            "facts_count": len(self.current_session.collected_facts),
            "agents_used": list(self.current_session.agent_outputs.keys()),
            "key_facts": list(self.current_session.collected_facts.keys())[:10],
            "timestamp": datetime.datetime.now().isoformat()
        }
        
        self.learning_records.append(pattern)
        
        # ä¿å­˜åˆ°åŸºç¡€è®°å¿†
        if self.base_manager:
            self.base_manager.save_research_experience(
                industry=self.current_session.industry,
                dimension="ç»¼åˆ",
                insight=f"æˆåŠŸå®Œæˆ{self.current_session.industry}è¡Œä¸šç ”ç©¶ï¼Œæ”¶é›†{len(self.current_session.collected_facts)}ä¸ªå…³é”®äº‹å®",
                success=True
            )
        
        print(f"ğŸ“š [EnhancedMemory] å­¦ä¹ æˆåŠŸæ¨¡å¼: {self.current_session.industry}")
    
    def get_similar_research(self, industry: str, k: int = 3) -> List[Dict]:
        """
        è·å–ç›¸ä¼¼çš„å†å²ç ”ç©¶
        
        Args:
            industry: è¡Œä¸š
            k: è¿”å›æ•°é‡
        
        Returns:
            List[Dict]: ç›¸ä¼¼ç ”ç©¶åˆ—è¡¨
        """
        similar = []
        
        # ä»ä¼šè¯å†å²ä¸­æŸ¥æ‰¾
        for session in reversed(self.session_history):
            if session.industry == industry and session.status == "completed":
                similar.append({
                    "session_id": session.session_id,
                    "province": session.province,
                    "target_year": session.target_year,
                    "data_coverage": session.data_coverage,
                    "facts_count": len(session.collected_facts)
                })
                if len(similar) >= k:
                    break
        
        # ä»åŸºç¡€è®°å¿†ä¸­è¡¥å……
        if self.base_manager and len(similar) < k:
            base_results = self.base_manager.recall_similar_reports(industry, k=k-len(similar))
            for result in base_results:
                similar.append({
                    "content_preview": result.get("content", "")[:200],
                    "metadata": result.get("metadata", {})
                })
        
        return similar
    
    def export_session_data(self, output_path: str):
        """å¯¼å‡ºä¼šè¯æ•°æ®"""
        if not self.current_session:
            print("âš ï¸ æ— æ´»åŠ¨ä¼šè¯")
            return
        
        data = {
            "session_id": self.current_session.session_id,
            "industry": self.current_session.industry,
            "province": self.current_session.province,
            "target_year": self.current_session.target_year,
            "focus": self.current_session.focus,
            "start_time": self.current_session.start_time,
            "collected_facts": self.current_session.collected_facts,
            "quality_scores": self.current_session.quality_scores,
            "global_facts": self.ctx_manager.get_all_facts(),
            "conflicts": self.ctx_manager.get_conflicts()
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“¤ [EnhancedMemory] ä¼šè¯æ•°æ®å·²å¯¼å‡º: {output_path}")


class FactValidationMiddleware:
    """
    äº‹å®éªŒè¯ä¸­é—´ä»¶
    åœ¨Agentè¾“å‡ºå‰è¿›è¡Œäº‹å®æ ¸æŸ¥
    """
    
    def __init__(self, memory_manager: EnhancedMemoryManager):
        self.memory = memory_manager
    
    def validate_before_write(self, content: str, agent_name: str) -> Tuple[bool, str, List[str]]:
        """
        å†™ä½œå‰éªŒè¯
        
        Args:
            content: å¾…éªŒè¯å†…å®¹
            agent_name: Agentåç§°
        
        Returns:
            Tuple[bool, str, List[str]]: (æ˜¯å¦é€šè¿‡, ä¿®æ­£åå†…å®¹, é—®é¢˜åˆ—è¡¨)
        """
        # æ£€æŸ¥ä¸€è‡´æ€§
        check_result = self.memory.check_consistency(content)
        
        issues = []
        corrected_content = content
        
        if not check_result["passed"]:
            for issue in check_result["issues"]:
                issues.append(
                    f"æ•°æ®ä¸ä¸€è‡´: {issue['fact_key']} æœŸæœ›å€¼={issue['expected']}, å‘ç°å€¼={issue['found']}"
                )
                
                # å°è¯•è‡ªåŠ¨ä¿®æ­£
                try:
                    corrected_content = corrected_content.replace(
                        str(issue['found']),
                        str(issue['expected'])
                    )
                except:
                    pass
        
        return check_result["passed"], corrected_content, issues
    
    def validate_after_research(self, research_output: str) -> Dict[str, Any]:
        """
        ç ”ç©¶åéªŒè¯
        
        Args:
            research_output: ç ”ç©¶è¾“å‡º
        
        Returns:
            Dict: éªŒè¯ç»“æœ
        """
        # è·å–æ•°æ®è¦†ç›–ç‡
        coverage = self.memory.get_data_coverage()
        
        # æ£€æŸ¥ä¸€è‡´æ€§
        consistency = self.memory.check_consistency(research_output)
        
        return {
            "data_coverage": coverage,
            "consistency_check": consistency,
            "overall_passed": coverage.get("pass_threshold", False) and consistency.get("passed", False)
        }


# å…¨å±€å®ä¾‹
try:
    from memory_system.memory_manager import memory_manager as base_memory
    enhanced_memory = EnhancedMemoryManager(base_memory)
except ImportError:
    enhanced_memory = EnhancedMemoryManager(None)

fact_validation = FactValidationMiddleware(enhanced_memory)
