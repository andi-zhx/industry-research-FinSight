# agent_system/postprocess/planner_parser.py
# Planner Parser çš„èŒè´£ï¼š
# æŠŠ Planner çš„è‡ªç„¶è¯­è¨€è¾“å‡º â†’ ç¨³å®šç»“æ„åŒ–
# ä¸ºåç»­ Agent æä¾›ç¡¬çº¦æŸè¾“å…¥
# åœ¨æ—©æœŸå°±å‘ç°â€œè¿™ä»½è§„åˆ’ä¸å¯æ‰§è¡Œâ€å¹¶ç›´æ¥æŠ¥é”™

# agent_system/postprocess/planner_parser.py
import re
from typing import List, Dict

def parse_planner_output(text: str) -> Dict:
    """
    å°† Planner çš„è‡ªç„¶è¯­è¨€ç ”ç©¶è“å›¾è§£æä¸ºç¨³å®šç»“æ„ã€‚
    ã€æ ¸å¿ƒæ”¹è¿›ã€‘ï¼šå¤§å¹…å¢åŠ å®¹é”™æ€§ï¼Œå…³é”®å­—æ®µåŒ¹é…å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤å€¼ï¼Œä¸å†æŠ›å‡ºå¼‚å¸¸ä¸­æ–­æµç¨‹ã€‚
    """
    if not text:
        text = ""

    # åˆå§‹åŒ–é»˜è®¤ç»“æ„
    result = {
        "raw_text": text,
        "total_word_target": 10000, # é»˜è®¤å€¼ï¼Œé˜²æ­¢æŠ¥é”™
        "chapters": [],
        "tables": [],
        "parallel_chapters": [],
        "data_dependent_chapters": []
    }

    # =========================================================
    # 1ï¸âƒ£ æå–ã€Œé¢„æœŸæ€»å­—æ•°ã€ (å¢åŠ å®¹é”™)
    # =========================================================
    # åŒ¹é…æ¨¡å¼ï¼šå…è®¸ "é¢„æœŸæ€»å­—æ•°" åæœ‰ç©ºæ ¼ã€å†’å·ã€ä¸­æ–‡å†’å·ã€ç”šè‡³ "çº¦" å­—
    # ç¤ºä¾‹åŒ¹é…ï¼š "é¢„æœŸæ€»å­—æ•°ï¼š12,000" / "**é¢„æœŸæ€»å­—æ•°**: çº¦ 10000" / "é¢„è®¡å­—æ•°ï¼š1ä¸‡"
    total_word_match = re.search(r"(é¢„æœŸæ€»å­—æ•°|é¢„è®¡å­—æ•°|æ€»å­—æ•°).*?[:ï¼š].*?(\d[\d,]*)", text)
    if total_word_match:
        try:
            num_str = total_word_match.group(2).replace(",", "")
            result["total_word_target"] = int(num_str)
        except:
            pass # è§£æå¤±è´¥å°±ç”¨é»˜è®¤å€¼ 10000

    # =========================================================
    # 2ï¸âƒ£ æŒ‰ç« èŠ‚æ‹†åˆ†ï¼ˆå¢å¼ºç‰ˆæ­£åˆ™ï¼‰
    # =========================================================
    # å°è¯•å¤šç§åˆ†å‰²æ¨¡å¼
    # æ¨¡å¼ A: ## ç¬¬1ç«  (Markdown æ ‡å‡†)
    chapter_blocks = re.split(r"\n#+\s*ç¬¬\d+ç« ", text)
    
    # å¦‚æœåˆ†å‰²å¤±è´¥ï¼ˆåªæœ‰ä¸€æ®µï¼‰ï¼Œå°è¯• æ¨¡å¼ B: ç¬¬1ç«  (æ²¡æœ‰#å·)
    if len(chapter_blocks) <= 1:
        chapter_blocks = re.split(r"\n\s*ç¬¬\d+ç« ", text)

    # ç¬¬ä¸€ä¸ª block é€šå¸¸æ˜¯â€œä¸€ã€æŠ¥å‘Šæ€»ä½“è§„åˆ’â€ç­‰å‰ç½®ä¿¡æ¯ï¼Œè·³è¿‡
    for block in chapter_blocks[1:]:
        if len(block.strip()) < 10: continue # è·³è¿‡è¿‡çŸ­çš„ç¢ç‰‡
        try:
            chapter = _parse_single_chapter(block)
            result["chapters"].append(chapter)
            result["tables"].extend(chapter["tables"])
        except Exception as e:
            print(f"âš ï¸ [Parser Warning] è·³è¿‡ä¸€ä¸ªæ— æ³•è§£æçš„ç« èŠ‚å—: {str(e)}")
            continue

    # ä¿åº•ï¼šå¦‚æœçœŸçš„ä¸€ä¸ªç« èŠ‚éƒ½æ²¡è§£å‡ºæ¥ï¼ˆéå¸¸ç½•è§ï¼‰ï¼Œæ‰‹åŠ¨é€ ä¸€ä¸ªé»˜è®¤ç« èŠ‚ï¼Œé˜²æ­¢ä¸‹æ¸¸ crash
    if not result["chapters"]:
        result["chapters"].append({
            "title": "ç»¼åˆåˆ†æ",
            "word_target": 2000,
            "research_questions": ["è¡Œä¸šç°çŠ¶åˆ†æ"],
            "data_sources": "å…¬å¼€ç½‘ç»œæ•°æ®",
            "tables": []
        })

    # =========================================================
    # 3ï¸âƒ£ æå–å¹¶è¡Œ/ä¾èµ–ä¿¡æ¯ (å¼±çº¦æŸï¼Œæ‰¾ä¸åˆ°å°±ç©ºç€)
    # =========================================================
    try:
        parallel_match = re.search(r"å¹¶è¡Œå†™ä½œç« èŠ‚.*?[:ï¼š]\s*(.*)", text, re.DOTALL)
        if parallel_match:
            # å–ç¬¬ä¸€è¡Œï¼Œé˜²æ­¢åŒ¹é…åˆ°åé¢å¤ªå¤šå†…å®¹
            line = parallel_match.group(1).split('\n')[0]
            result["parallel_chapters"] = _split_list(line)

        data_dep_match = re.search(r"å¼ºä¾èµ–æ•°æ®çš„ç« èŠ‚.*?[:ï¼š]\s*(.*)", text, re.DOTALL)
        if data_dep_match:
            line = data_dep_match.group(1).split('\n')[0]
            result["data_dependent_chapters"] = _split_list(line)
    except:
        pass

    # ç»™ Reviewer / QA ç”¨çš„æ£€æŸ¥æ¸…å•
    result["qa_checklist"] = {
        "total_word_target": result["total_word_target"],
        "chapter_count": len(result["chapters"]),
        "chapters": [
            {
                "title": c["title"],
                "min_word_target": c["min_word_target"],
                "require_table": c["require_table"]
            }
            for c in result["chapters"]
        ]
    }


    return result


# =========================================================
# ğŸ”§ è¾…åŠ©å‡½æ•°
# =========================================================

def _parse_single_chapter(block: str) -> Dict:
    """
    è§£æå•ä¸€ç« èŠ‚å†…å®¹ (å®½å®¹æ¨¡å¼)
    """
    chapter = {
        "title": "æœªå‘½åç« èŠ‚",
        "word_target": 1500,
        "research_questions": [],
        "data_sources": "",
        "tables": []
    }

    # 1. ç« èŠ‚æ ‡é¢˜
    # å–ç¬¬ä¸€è¡Œéç©ºæ–‡æœ¬ä½œä¸ºæ ‡é¢˜
    lines = [l.strip() for l in block.strip().split('\n') if l.strip()]
    if lines:
        # å»æ‰å¯èƒ½çš„å†’å·æˆ–å¤šä½™ç¬¦å·
        raw_title = lines[0].lstrip("ï¼š:").strip()
        # æœ‰æ—¶å€™æ ‡é¢˜ä¼šå¸¦ "1. è¡Œä¸šæ¦‚å†µ"ï¼Œå»æ‰å‰é¢çš„æ•°å­—
        chapter["title"] = re.sub(r"^[\d\.]+\s*", "", raw_title)

    # 2. ç›®æ ‡å­—æ•°
    word_match = re.search(r"(ç›®æ ‡å­—æ•°|å­—æ•°).*?[:ï¼š].*?(\d[\d,]*)", block)
    if word_match:
        try:
            chapter["word_target"] = int(word_match.group(2).replace(",", ""))
        except:
            pass

    # 3. å…³é”®ç ”ç©¶é—®é¢˜
    rq_match = re.search(
        r"å…³é”®ç ”ç©¶é—®é¢˜.*?[:ï¼š](.*?)(æ•°æ®ä¸ä¿¡æ¯æ¥æºæŒ‡å¼•|è¡¨æ ¼è§„åˆ’|#|$)",
        block,
        re.DOTALL
    )
    if rq_match:
        chapter["research_questions"] = _split_list(rq_match.group(1))

    # 4. æ•°æ®æ¥æº
    ds_match = re.search(
        r"æ•°æ®ä¸ä¿¡æ¯æ¥æºæŒ‡å¼•.*?[:ï¼š](.*?)(è¡¨æ ¼è§„åˆ’|#|$)",
        block,
        re.DOTALL
    )
    if ds_match:
        chapter["data_sources"] = ds_match.group(1).strip()

    # 5. è¡¨æ ¼è§„åˆ’ (æœ€å®¹æ˜“å‡ºé”™çš„åœ°æ–¹ï¼ŒåŠ é‡å®¹é”™)
    # åŒ¹é… "è¡¨ 1-1" æˆ– "è¡¨æ ¼ 1" å¼€å¤´çš„æ®µè½
    table_blocks = re.findall(
        r"(è¡¨\s*[\d\-\.]+|è¡¨æ ¼\s*[\d\-\.]+).*?[:ï¼š](.*?)(?=è¡¨\s*[\d\-\.]+|è¡¨æ ¼\s*[\d\-\.]+|#|$)",
        block,
        re.DOTALL
    )

    for header, content in table_blocks:
        try:
            parsed_table = _parse_table(content)
            # æŠŠè¡¨å·æ‹¼è¿›å»æ–¹ä¾¿é˜…è¯»
            parsed_table["name"] = f"{header} {parsed_table['name']}"
            chapter["tables"].append(parsed_table)
        except:
            continue

    # ã€é‡è¦ã€‘ä¸å†å› ä¸ºæ²¡æœ‰è¡¨æ ¼è€ŒæŠ¥é”™

    # 6ï¸âƒ£ æœ€ä½å­—æ•°ç¡¬çº¦æŸï¼ˆPlanner å¼ºåˆ¶ Writer ç”¨ï¼‰
    chapter["min_word_target"] = max(800, int(chapter["word_target"] * 0.8))

    # 7ï¸âƒ£ æ˜¯å¦å¼ºåˆ¶è¦æ±‚è¡¨æ ¼
    chapter["require_table"] = True if chapter["tables"] else False


    return chapter


def _parse_table(text: str) -> Dict:
    """
    è§£æå•ä¸ªè¡¨æ ¼å®šä¹‰
    """
    table = {
        "name": "æ•°æ®è¡¨",
        "purpose": "å±•ç¤ºæ•°æ®",
        "fields": []
    }

    # æå–åç§°
    name_match = re.search(r"è¡¨æ ¼åç§°.*?[:ï¼š](.*)", text)
    if name_match:
        table["name"] = name_match.group(1).strip()

    # æå–ç”¨é€”
    purpose_match = re.search(r"ç”¨é€”.*?[:ï¼š](.*)", text)
    if purpose_match:
        table["purpose"] = purpose_match.group(1).strip()

    # æå–å­—æ®µ
    fields_match = re.search(r"(æ ¸å¿ƒå­—æ®µ|åˆ—å).*?[:ï¼š](.*)", text)
    if fields_match:
        table["fields"] = _split_list(fields_match.group(1))

    # åªè¦æœ‰å­—æ®µå°±ç®—æˆåŠŸï¼Œåç§°ç¨å¾®å®½å®¹ç‚¹
    if not table["fields"]:
        # å°è¯•çœ‹çœ‹æœ‰æ²¡æœ‰ markdown list
        potential_fields = _split_list(text)
        # å¦‚æœåˆ—è¡¨ä¸­åŒ…å« "åŒæ¯”" "å æ¯”" ç­‰è¯ï¼Œå¤§æ¦‚ç‡æ˜¯å­—æ®µ
        if len(potential_fields) >= 1:
             table["fields"] = potential_fields

    return table


def _split_list(text: str) -> List[str]:
    """
    å°† - / æ•°å­—åˆ—è¡¨ / æ¢è¡Œ ç»Ÿä¸€æ‹†æˆ list
    """
    items = []
    for line in text.splitlines():
        line = line.strip()
        if not line:
            continue
        # å»æ‰è¡Œé¦–çš„ "1.", "-", "*", "â€¢" ç­‰ç¬¦å·
        line = re.sub(r"^[\-\*\â€¢\d\.\ã€]+", "", line).strip()
        if line:
            items.append(line)
    return items

