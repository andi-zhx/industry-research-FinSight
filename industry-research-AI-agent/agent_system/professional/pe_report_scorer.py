# agent_system/professional/pe_report_scorer.py
"""
PEçº§è¡Œä¸šç ”æŠ¥è¯„åˆ†ä¸è¡¥å¼ºæ¸…å•
æä¾›ä¸“ä¸šçº§ç ”æŠ¥è´¨é‡è¯„ä¼°å’Œæ”¹è¿›å»ºè®®

è¯„åˆ†ç»´åº¦ï¼š
1. æ•°æ®å¯ä¿¡åº¦ï¼ˆé”šå®šå‹æ•°æ®ï¼‰
2. æ ‡çš„æ·±æ‹†ï¼ˆå…¬å¸çº§åˆ†æï¼‰
3. ä¼°å€¼ä¸å›æŠ¥ï¼ˆè´¢åŠ¡æŠ•èµ„è¯­è¨€ï¼‰
4. é£é™©åˆ†æï¼ˆé¡¹ç›®çº§å¾®è§‚é£é™©ï¼‰
5. è§‚ç‚¹å·®å¼‚åŒ–ï¼ˆåå…±è¯†åˆ¤æ–­ï¼‰
"""

from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import re


class ReportLevel(Enum):
    """ç ”æŠ¥ç­‰çº§"""
    L1 = "L1-åŸºç¡€è¡Œç ”"      # ä¸‰å››çº¿åˆ¸å•†/å’¨è¯¢å…¬å¸æ¨¡æ¿
    L2 = "L2-ä¸»æµè¡Œç ”"      # ä¸»æµåˆ¸å•†è¡Œä¸šåˆ†æå¸ˆå¸¸è§„æŠ¥å‘Š
    L3 = "L3-ä¸“ä¸šè¡Œç ”"      # ä¸€çº¿PE/äº§ä¸šèµ„æœ¬å†…éƒ¨ç ”ç©¶
    L4 = "L4-é¡¶çº§è¡Œç ”"      # å¤´éƒ¨PE/ä¸€çº¿åˆ¸å•†é¦–å¸­çº§æ·±åº¦æŠ¥å‘Š


class ScoreDimension(Enum):
    """è¯„åˆ†ç»´åº¦"""
    DATA_CREDIBILITY = "æ•°æ®å¯ä¿¡åº¦"
    COMPANY_DEEP_DIVE = "æ ‡çš„æ·±æ‹†"
    VALUATION_RETURN = "ä¼°å€¼ä¸å›æŠ¥"
    RISK_ANALYSIS = "é£é™©åˆ†æ"
    CONTRARIAN_VIEWS = "è§‚ç‚¹å·®å¼‚åŒ–"
    INVESTMENT_ORIENTATION = "æŠ•èµ„å¯¼å‘"
    WRITING_QUALITY = "å†™ä½œè´¨é‡"


@dataclass
class DimensionScore:
    """ç»´åº¦è¯„åˆ†"""
    dimension: ScoreDimension
    score: float                # 0-100
    weight: float               # æƒé‡
    strengths: List[str] = field(default_factory=list)  # ä¼˜ç‚¹
    weaknesses: List[str] = field(default_factory=list)  # ä¸è¶³
    improvements: List[str] = field(default_factory=list)  # æ”¹è¿›å»ºè®®
    
    def get_weighted_score(self) -> float:
        return self.score * self.weight


@dataclass
class ReportScoreCard:
    """ç ”æŠ¥è¯„åˆ†å¡"""
    report_title: str
    dimension_scores: List[DimensionScore] = field(default_factory=list)
    overall_score: float = 0
    report_level: ReportLevel = ReportLevel.L2
    
    # å…³é”®ç¼ºå¤±
    critical_gaps: List[str] = field(default_factory=list)
    
    # è¡¥å¼ºæ¸…å•
    enhancement_checklist: List[Dict] = field(default_factory=list)
    
    def calculate_overall_score(self):
        """è®¡ç®—ç»¼åˆå¾—åˆ†"""
        if not self.dimension_scores:
            return
        
        total_weighted = sum(ds.get_weighted_score() for ds in self.dimension_scores)
        total_weight = sum(ds.weight for ds in self.dimension_scores)
        
        self.overall_score = total_weighted / total_weight if total_weight > 0 else 0
        
        # ç¡®å®šç­‰çº§
        if self.overall_score >= 85:
            self.report_level = ReportLevel.L4
        elif self.overall_score >= 70:
            self.report_level = ReportLevel.L3
        elif self.overall_score >= 55:
            self.report_level = ReportLevel.L2
        else:
            self.report_level = ReportLevel.L1
    
    def generate_scorecard_report(self) -> str:
        """ç”Ÿæˆè¯„åˆ†æŠ¥å‘Š"""
        self.calculate_overall_score()
        
        report = f"# {self.report_title} è´¨é‡è¯„ä¼°æŠ¥å‘Š\n\n"
        
        # æ€»ä½“è¯„åˆ†
        report += "## ä¸€ã€æ€»ä½“è¯„åˆ†\n\n"
        report += f"**ç»¼åˆå¾—åˆ†**ï¼š{self.overall_score:.1f}/100\n\n"
        report += f"**ç ”æŠ¥ç­‰çº§**ï¼š{self.report_level.value}\n\n"
        
        # ç­‰çº§è¯´æ˜
        report += "| ç­‰çº§ | è¯´æ˜ | åˆ†æ•°åŒºé—´ |\n"
        report += "|------|------|----------|\n"
        report += "| L4-é¡¶çº§è¡Œç ” | å¤´éƒ¨PE/ä¸€çº¿åˆ¸å•†é¦–å¸­çº§ | 85+ |\n"
        report += "| L3-ä¸“ä¸šè¡Œç ” | ä¸€çº¿PE/äº§ä¸šèµ„æœ¬å†…éƒ¨ç ”ç©¶ | 70-84 |\n"
        report += "| L2-ä¸»æµè¡Œç ” | ä¸»æµåˆ¸å•†è¡Œä¸šåˆ†æå¸ˆ | 55-69 |\n"
        report += "| L1-åŸºç¡€è¡Œç ” | ä¸‰å››çº¿åˆ¸å•†/å’¨è¯¢å…¬å¸ | <55 |\n\n"
        
        # ç»´åº¦è¯„åˆ†
        report += "## äºŒã€ç»´åº¦è¯„åˆ†\n\n"
        report += "| ç»´åº¦ | å¾—åˆ† | æƒé‡ | åŠ æƒå¾—åˆ† |\n"
        report += "|------|------|------|----------|\n"
        
        for ds in self.dimension_scores:
            weighted = ds.get_weighted_score()
            report += f"| {ds.dimension.value} | {ds.score:.0f} | {ds.weight:.0%} | {weighted:.1f} |\n"
        
        report += "\n"
        
        # å„ç»´åº¦è¯¦æƒ…
        report += "## ä¸‰ã€å„ç»´åº¦è¯¦æƒ…\n\n"
        
        for ds in self.dimension_scores:
            report += f"### {ds.dimension.value}ï¼ˆ{ds.score:.0f}åˆ†ï¼‰\n\n"
            
            if ds.strengths:
                report += "**ä¼˜ç‚¹**ï¼š\n"
                for s in ds.strengths:
                    report += f"- âœ… {s}\n"
                report += "\n"
            
            if ds.weaknesses:
                report += "**ä¸è¶³**ï¼š\n"
                for w in ds.weaknesses:
                    report += f"- âŒ {w}\n"
                report += "\n"
            
            if ds.improvements:
                report += "**æ”¹è¿›å»ºè®®**ï¼š\n"
                for i in ds.improvements:
                    report += f"- ğŸ’¡ {i}\n"
                report += "\n"
        
        # å…³é”®ç¼ºå¤±
        if self.critical_gaps:
            report += "## å››ã€å…³é”®ç¼ºå¤±ï¼ˆå¿…é¡»è¡¥é½ï¼‰\n\n"
            for i, gap in enumerate(self.critical_gaps, 1):
                report += f"{i}. âš ï¸ {gap}\n"
            report += "\n"
        
        # è¡¥å¼ºæ¸…å•
        if self.enhancement_checklist:
            report += "## äº”ã€è¡¥å¼ºæ¸…å•\n\n"
            report += "| ä¼˜å…ˆçº§ | è¡¥å¼ºé¡¹ | é¢„æœŸæå‡ | å·¥ä½œé‡ |\n"
            report += "|--------|--------|----------|--------|\n"
            
            for item in self.enhancement_checklist:
                report += f"| {item['priority']} | {item['item']} | +{item['score_boost']}åˆ† | {item['effort']} |\n"
        
        return report


class PEReportScorer:
    """PEçº§ç ”æŠ¥è¯„åˆ†å™¨"""
    
    # è¯„åˆ†æ ‡å‡†
    SCORING_CRITERIA = {
        ScoreDimension.DATA_CREDIBILITY: {
            "weight": 0.25,
            "criteria": {
                "tier1_data_ratio": "ä¸€çº§æ¥æºæ•°æ®å æ¯”",
                "data_breakdown": "æ•°æ®æ‹†è§£å®Œæ•´æ€§",
                "cross_validation": "äº¤å‰éªŒè¯",
                "source_citation": "æ¥æºæ ‡æ³¨è§„èŒƒæ€§"
            },
            "max_scores": {
                "tier1_data_ratio": 30,
                "data_breakdown": 30,
                "cross_validation": 20,
                "source_citation": 20
            }
        },
        ScoreDimension.COMPANY_DEEP_DIVE: {
            "weight": 0.20,
            "criteria": {
                "revenue_breakdown": "æ”¶å…¥ç»“æ„æ‹†è§£",
                "financial_analysis": "è´¢åŠ¡æ·±åº¦åˆ†æ",
                "competitive_comparison": "ç«äº‰å¯¹æ¯”é‡åŒ–",
                "ai_analysis": "AIç›¸å…³åˆ†æ"
            },
            "max_scores": {
                "revenue_breakdown": 30,
                "financial_analysis": 30,
                "competitive_comparison": 25,
                "ai_analysis": 15
            }
        },
        ScoreDimension.VALUATION_RETURN: {
            "weight": 0.20,
            "criteria": {
                "valuation_methods": "ä¼°å€¼æ–¹æ³•å¤šæ ·æ€§",
                "return_scenarios": "å›æŠ¥æƒ…æ™¯åˆ†æ",
                "irr_moic": "IRR/MOICè®¡ç®—",
                "investor_fit": "æŠ•èµ„è€…é€‚é…"
            },
            "max_scores": {
                "valuation_methods": 30,
                "return_scenarios": 30,
                "irr_moic": 25,
                "investor_fit": 15
            }
        },
        ScoreDimension.RISK_ANALYSIS: {
            "weight": 0.15,
            "criteria": {
                "micro_risks": "å¾®è§‚é£é™©è¯†åˆ«",
                "quantified_risks": "é£é™©é‡åŒ–",
                "chain_risks": "äº§ä¸šé“¾é£é™©",
                "monitoring_kpis": "ç›‘æ§æŒ‡æ ‡"
            },
            "max_scores": {
                "micro_risks": 30,
                "quantified_risks": 30,
                "chain_risks": 25,
                "monitoring_kpis": 15
            }
        },
        ScoreDimension.CONTRARIAN_VIEWS: {
            "weight": 0.10,
            "criteria": {
                "consensus_identification": "å…±è¯†è¯†åˆ«",
                "contrarian_arguments": "åå…±è¯†è®ºè¯",
                "evidence_support": "è¯æ®æ”¯æ’‘",
                "investment_implications": "æŠ•èµ„å«ä¹‰"
            },
            "max_scores": {
                "consensus_identification": 25,
                "contrarian_arguments": 35,
                "evidence_support": 25,
                "investment_implications": 15
            }
        },
        ScoreDimension.INVESTMENT_ORIENTATION: {
            "weight": 0.05,
            "criteria": {
                "tam_analysis": "TAMåˆ†æ",
                "value_chain": "ä»·å€¼é“¾åˆ†é…",
                "exit_path": "é€€å‡ºè·¯å¾„",
                "investor_type_fit": "æŠ•èµ„è€…ç±»å‹é€‚é…"
            },
            "max_scores": {
                "tam_analysis": 25,
                "value_chain": 30,
                "exit_path": 25,
                "investor_type_fit": 20
            }
        },
        ScoreDimension.WRITING_QUALITY: {
            "weight": 0.05,
            "criteria": {
                "logic_flow": "é€»è¾‘æµç•…æ€§",
                "professional_language": "ä¸“ä¸šè¯­è¨€",
                "no_ai_slop": "æ— AIæ°´æ–‡",
                "actionable": "å¯æ“ä½œæ€§"
            },
            "max_scores": {
                "logic_flow": 25,
                "professional_language": 25,
                "no_ai_slop": 25,
                "actionable": 25
            }
        }
    }
    
    def __init__(self):
        pass
    
    def score_report(self, report_content: str, report_title: str = "è¡Œä¸šç ”ç©¶æŠ¥å‘Š") -> ReportScoreCard:
        """è¯„åˆ†ç ”æŠ¥"""
        
        scorecard = ReportScoreCard(report_title=report_title)
        
        # è¯„ä¼°å„ç»´åº¦
        for dimension, config in self.SCORING_CRITERIA.items():
            ds = self._score_dimension(report_content, dimension, config)
            scorecard.dimension_scores.append(ds)
        
        # è¯†åˆ«å…³é”®ç¼ºå¤±
        scorecard.critical_gaps = self._identify_critical_gaps(report_content)
        
        # ç”Ÿæˆè¡¥å¼ºæ¸…å•
        scorecard.enhancement_checklist = self._generate_enhancement_checklist(scorecard)
        
        # è®¡ç®—æ€»åˆ†
        scorecard.calculate_overall_score()
        
        return scorecard
    
    def _score_dimension(
        self,
        content: str,
        dimension: ScoreDimension,
        config: Dict
    ) -> DimensionScore:
        """è¯„ä¼°å•ä¸ªç»´åº¦"""
        
        score = 0
        strengths = []
        weaknesses = []
        improvements = []
        
        criteria = config["criteria"]
        max_scores = config["max_scores"]
        
        # æ•°æ®å¯ä¿¡åº¦è¯„ä¼°
        if dimension == ScoreDimension.DATA_CREDIBILITY:
            # æ£€æŸ¥ä¸€çº§æ¥æº
            tier1_keywords = ["ç»Ÿè®¡å±€", "å¹´æŠ¥", "å…¬å‘Š", "Wind", "Bloomberg", "å¤®è¡Œ", "è¯ç›‘ä¼š"]
            tier1_count = sum(1 for kw in tier1_keywords if kw in content)
            if tier1_count >= 5:
                score += max_scores["tier1_data_ratio"]
                strengths.append("ä½¿ç”¨äº†å¤šä¸ªä¸€çº§æ•°æ®æ¥æº")
            elif tier1_count >= 2:
                score += max_scores["tier1_data_ratio"] * 0.6
                weaknesses.append("ä¸€çº§æ•°æ®æ¥æºä¸å¤Ÿå……åˆ†")
                improvements.append("å¢åŠ å®˜æ–¹ç»Ÿè®¡å’Œä¸Šå¸‚å…¬å¸å…¬å‘Šå¼•ç”¨")
            else:
                score += max_scores["tier1_data_ratio"] * 0.3
                weaknesses.append("ç¼ºå°‘ä¸€çº§æ•°æ®æ¥æº")
                improvements.append("å¿…é¡»è¡¥å……å®˜æ–¹ç»Ÿè®¡å’Œä¸Šå¸‚å…¬å¸å¹´æŠ¥æ•°æ®")
            
            # æ£€æŸ¥æ•°æ®æ‹†è§£
            if "æ‹†è§£" in content or "ç»†åˆ†" in content or "å…¶ä¸­ï¼š" in content:
                score += max_scores["data_breakdown"]
                strengths.append("æœ‰æ•°æ®æ‹†è§£")
            else:
                weaknesses.append("ç¼ºå°‘æ•°æ®æ‹†è§£")
                improvements.append("å¯¹å¸‚åœºè§„æ¨¡ç­‰æ ¸å¿ƒæ•°æ®è¿›è¡Œç»†åˆ†æ‹†è§£")
            
            # æ£€æŸ¥äº¤å‰éªŒè¯
            if "éªŒè¯" in content or "å¯¹æ¯”" in content:
                score += max_scores["cross_validation"]
            else:
                weaknesses.append("ç¼ºå°‘äº¤å‰éªŒè¯")
                improvements.append("å¯¹å…³é”®æ•°æ®è¿›è¡Œå¤šæ¥æºäº¤å‰éªŒè¯")
            
            # æ£€æŸ¥æ¥æºæ ‡æ³¨
            if "æ¥æºï¼š" in content or "æ•°æ®æ¥æº" in content:
                score += max_scores["source_citation"]
                strengths.append("æœ‰æ¥æºæ ‡æ³¨")
            else:
                weaknesses.append("æ¥æºæ ‡æ³¨ä¸è§„èŒƒ")
                improvements.append("ä¸ºæ¯ä¸ªå…³é”®æ•°æ®æ ‡æ³¨æ¥æº")
        
        # æ ‡çš„æ·±æ‹†è¯„ä¼°
        elif dimension == ScoreDimension.COMPANY_DEEP_DIVE:
            # æ£€æŸ¥æ”¶å…¥ç»“æ„
            if "æ”¶å…¥ç»“æ„" in content or "ä¸šåŠ¡æ¿å—" in content or "è¥æ”¶å æ¯”" in content:
                score += max_scores["revenue_breakdown"]
                strengths.append("æœ‰æ”¶å…¥ç»“æ„åˆ†æ")
            else:
                weaknesses.append("ç¼ºå°‘æ”¶å…¥ç»“æ„æ‹†è§£")
                improvements.append("æ·»åŠ é‡ç‚¹å…¬å¸çš„æ”¶å…¥ç»“æ„æ‹†è§£")
            
            # æ£€æŸ¥è´¢åŠ¡åˆ†æ
            financial_keywords = ["ROE", "æ¯›åˆ©ç‡", "å‡€åˆ©ç‡", "æœé‚¦", "ç°é‡‘æµ"]
            financial_count = sum(1 for kw in financial_keywords if kw in content)
            if financial_count >= 3:
                score += max_scores["financial_analysis"]
                strengths.append("è´¢åŠ¡åˆ†ææ·±å…¥")
            elif financial_count >= 1:
                score += max_scores["financial_analysis"] * 0.5
                weaknesses.append("è´¢åŠ¡åˆ†æä¸å¤Ÿæ·±å…¥")
                improvements.append("æ·»åŠ æœé‚¦åˆ†æå’Œç°é‡‘æµåˆ†æ")
            else:
                weaknesses.append("ç¼ºå°‘è´¢åŠ¡æ·±åº¦åˆ†æ")
                improvements.append("å¿…é¡»æ·»åŠ æ ¸å¿ƒè´¢åŠ¡æŒ‡æ ‡åˆ†æ")
            
            # æ£€æŸ¥ç«äº‰å¯¹æ¯”
            if "ç«äº‰å¯¹æ¯”" in content or "vs" in content.lower() or "å¯¹æ¯”" in content:
                score += max_scores["competitive_comparison"]
                strengths.append("æœ‰ç«äº‰å¯¹æ¯”")
            else:
                weaknesses.append("ç¼ºå°‘é‡åŒ–ç«äº‰å¯¹æ¯”")
                improvements.append("æ·»åŠ ä¸ç«äº‰å¯¹æ‰‹çš„é‡åŒ–å¯¹æ¯”è¡¨æ ¼")
            
            # æ£€æŸ¥AIåˆ†æ
            if "AI" in content and ("å æ¯”" in content or "æ”¶å…¥" in content):
                score += max_scores["ai_analysis"]
        
        # ä¼°å€¼ä¸å›æŠ¥è¯„ä¼°
        elif dimension == ScoreDimension.VALUATION_RETURN:
            # æ£€æŸ¥ä¼°å€¼æ–¹æ³•
            valuation_keywords = ["PE", "PB", "PS", "DCF", "EV/EBITDA"]
            valuation_count = sum(1 for kw in valuation_keywords if kw in content)
            if valuation_count >= 3:
                score += max_scores["valuation_methods"]
                strengths.append("ä½¿ç”¨å¤šç§ä¼°å€¼æ–¹æ³•")
            elif valuation_count >= 1:
                score += max_scores["valuation_methods"] * 0.5
                weaknesses.append("ä¼°å€¼æ–¹æ³•å•ä¸€")
                improvements.append("ä½¿ç”¨è‡³å°‘2-3ç§ä¼°å€¼æ–¹æ³•äº¤å‰éªŒè¯")
            else:
                weaknesses.append("ç¼ºå°‘ä¼°å€¼åˆ†æ")
                improvements.append("å¿…é¡»æ·»åŠ ä¼°å€¼é”šç‚¹åˆ†æ")
            
            # æ£€æŸ¥å›æŠ¥æƒ…æ™¯
            if "æƒ…æ™¯" in content or "ä¹è§‚" in content or "æ‚²è§‚" in content:
                score += max_scores["return_scenarios"]
                strengths.append("æœ‰æƒ…æ™¯åˆ†æ")
            else:
                weaknesses.append("ç¼ºå°‘å›æŠ¥æƒ…æ™¯åˆ†æ")
                improvements.append("æ·»åŠ ä¹è§‚/ä¸­æ€§/æ‚²è§‚ä¸‰ç§æƒ…æ™¯")
            
            # æ£€æŸ¥IRR/MOIC
            if "IRR" in content or "MOIC" in content or "å›æŠ¥ç‡" in content:
                score += max_scores["irr_moic"]
                strengths.append("æœ‰IRR/MOICè®¡ç®—")
            else:
                weaknesses.append("ç¼ºå°‘IRR/MOICè®¡ç®—")
                improvements.append("æ·»åŠ æŠ•èµ„å›æŠ¥ç‡æµ‹ç®—")
            
            # æ£€æŸ¥æŠ•èµ„è€…é€‚é…
            if "VC" in content or "PE" in content or "äº§ä¸šèµ„æœ¬" in content:
                score += max_scores["investor_fit"]
        
        # é£é™©åˆ†æè¯„ä¼°
        elif dimension == ScoreDimension.RISK_ANALYSIS:
            # æ£€æŸ¥å¾®è§‚é£é™©
            micro_risk_keywords = ["æµç‰‡å¤±è´¥", "å®¢æˆ·é›†ä¸­åº¦", "ç»­è´¹ç‡", "é¡¹ç›®è½¬äº§å“"]
            micro_count = sum(1 for kw in micro_risk_keywords if kw in content)
            if micro_count >= 2:
                score += max_scores["micro_risks"]
                strengths.append("æœ‰å¾®è§‚é£é™©åˆ†æ")
            elif "é£é™©" in content:
                score += max_scores["micro_risks"] * 0.5
                weaknesses.append("é£é™©åˆ†æåå®è§‚")
                improvements.append("æ·»åŠ é¡¹ç›®çº§å¾®è§‚é£é™©")
            else:
                weaknesses.append("ç¼ºå°‘é£é™©åˆ†æ")
                improvements.append("å¿…é¡»æ·»åŠ é£é™©åˆ†æç« èŠ‚")
            
            # æ£€æŸ¥é£é™©é‡åŒ–
            if "æ¦‚ç‡" in content or "%" in content:
                score += max_scores["quantified_risks"]
            else:
                weaknesses.append("é£é™©æœªé‡åŒ–")
                improvements.append("ä¸ºæ¯ä¸ªé£é™©æ·»åŠ æ¦‚ç‡å’Œå½±å“è¯„ä¼°")
            
            # æ£€æŸ¥äº§ä¸šé“¾é£é™©
            if "ä¸Šæ¸¸" in content and "é£é™©" in content:
                score += max_scores["chain_risks"]
            
            # æ£€æŸ¥ç›‘æ§æŒ‡æ ‡
            if "ç›‘æ§" in content or "KPI" in content:
                score += max_scores["monitoring_kpis"]
        
        # åå…±è¯†è§‚ç‚¹è¯„ä¼°
        elif dimension == ScoreDimension.CONTRARIAN_VIEWS:
            # æ£€æŸ¥å…±è¯†è¯†åˆ«
            if "å¸‚åœºæ™®éè®¤ä¸º" in content or "å…±è¯†" in content:
                score += max_scores["consensus_identification"]
                strengths.append("è¯†åˆ«äº†å¸‚åœºå…±è¯†")
            else:
                weaknesses.append("æœªæ˜ç¡®å¸‚åœºå…±è¯†")
                improvements.append("å…ˆæ˜ç¡®å¸‚åœºä¸»æµè§‚ç‚¹")
            
            # æ£€æŸ¥åå…±è¯†è®ºè¯
            if "æˆ‘ä»¬è®¤ä¸º" in content and ("ä¸åŒ" in content or "é”™è¯¯" in content):
                score += max_scores["contrarian_arguments"]
                strengths.append("æœ‰åå…±è¯†åˆ¤æ–­")
            else:
                weaknesses.append("ç¼ºå°‘åå…±è¯†è§‚ç‚¹")
                improvements.append("æ·»åŠ 1-2ä¸ªä¸å¸‚åœºä¸åŒçš„åˆ¤æ–­")
            
            # æ£€æŸ¥è¯æ®æ”¯æ’‘
            if "è¯æ®" in content or "æ•°æ®æ”¯æ’‘" in content:
                score += max_scores["evidence_support"]
            
            # æ£€æŸ¥æŠ•èµ„å«ä¹‰
            if "æŠ•èµ„å«ä¹‰" in content or "æŠ•èµ„å»ºè®®" in content:
                score += max_scores["investment_implications"]
        
        # æŠ•èµ„å¯¼å‘è¯„ä¼°
        elif dimension == ScoreDimension.INVESTMENT_ORIENTATION:
            if "TAM" in content or "å¸‚åœºè§„æ¨¡" in content:
                score += max_scores["tam_analysis"]
                strengths.append("æœ‰TAMåˆ†æ")
            
            if "ä»·å€¼é“¾" in content or "åˆ©æ¶¦åˆ†é…" in content:
                score += max_scores["value_chain"]
                strengths.append("æœ‰ä»·å€¼é“¾åˆ†æ")
            
            if "é€€å‡º" in content or "IPO" in content:
                score += max_scores["exit_path"]
            
            if "é€‚åˆ" in content and ("VC" in content or "PE" in content):
                score += max_scores["investor_type_fit"]
        
        # å†™ä½œè´¨é‡è¯„ä¼°
        elif dimension == ScoreDimension.WRITING_QUALITY:
            # ç®€å•è¯„ä¼°
            if len(content) > 5000:
                score += max_scores["logic_flow"]
            
            professional_terms = ["CAGR", "ROE", "PE", "ä¼°å€¼", "æ¯›åˆ©ç‡"]
            if sum(1 for t in professional_terms if t in content) >= 3:
                score += max_scores["professional_language"]
                strengths.append("ä½¿ç”¨ä¸“ä¸šæœ¯è¯­")
            
            # æ£€æŸ¥AIæ°´æ–‡
            ai_slop_patterns = ["æ€»ä¹‹", "ç»¼ä¸Šæ‰€è¿°", "ä¸è¨€è€Œå–»"]
            if sum(1 for p in ai_slop_patterns if p in content) < 3:
                score += max_scores["no_ai_slop"]
            else:
                weaknesses.append("å­˜åœ¨AIæ°´æ–‡ç—•è¿¹")
                improvements.append("å‡å°‘å¥—è¯ï¼Œå¢åŠ å®è´¨å†…å®¹")
            
            if "å»ºè®®" in content or "ç­–ç•¥" in content:
                score += max_scores["actionable"]
        
        return DimensionScore(
            dimension=dimension,
            score=score,
            weight=config["weight"],
            strengths=strengths,
            weaknesses=weaknesses,
            improvements=improvements
        )
    
    def _identify_critical_gaps(self, content: str) -> List[str]:
        """è¯†åˆ«å…³é”®ç¼ºå¤±"""
        gaps = []
        
        # æ£€æŸ¥æ ‡çš„æ·±æ‹†
        if "æ”¶å…¥ç»“æ„" not in content and "ä¸šåŠ¡æ¿å—" not in content:
            gaps.append("ç¼ºå°‘æ ‡çš„æ·±æ‹†æ¡ˆä¾‹ï¼ˆå¿…é¡»æ·»åŠ 1-2ä¸ªé‡ç‚¹å…¬å¸çš„æ·±åº¦åˆ†æï¼‰")
        
        # æ£€æŸ¥ä¼°å€¼æ¡†æ¶
        if "IRR" not in content and "MOIC" not in content:
            gaps.append("ç¼ºå°‘ä¼°å€¼ä¸å›æŠ¥æ¡†æ¶ï¼ˆå¿…é¡»æ·»åŠ IRR/MOICæµ‹ç®—ï¼‰")
        
        # æ£€æŸ¥åå…±è¯†
        if "æˆ‘ä»¬è®¤ä¸º" not in content or "å¸‚åœº" not in content:
            gaps.append("ç¼ºå°‘åå…±è¯†è§‚ç‚¹ï¼ˆå¿…é¡»æ·»åŠ 1-2ä¸ªå·®å¼‚åŒ–åˆ¤æ–­ï¼‰")
        
        return gaps
    
    def _generate_enhancement_checklist(self, scorecard: ReportScoreCard) -> List[Dict]:
        """ç”Ÿæˆè¡¥å¼ºæ¸…å•"""
        checklist = []
        
        for ds in scorecard.dimension_scores:
            if ds.score < 70:
                for improvement in ds.improvements[:2]:
                    checklist.append({
                        "priority": "é«˜" if ds.score < 50 else "ä¸­",
                        "item": improvement,
                        "score_boost": 5 if ds.score < 50 else 3,
                        "effort": "ä¸­ç­‰"
                    })
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        priority_order = {"é«˜": 0, "ä¸­": 1, "ä½": 2}
        checklist.sort(key=lambda x: priority_order.get(x["priority"], 2))
        
        return checklist[:10]  # æœ€å¤šè¿”å›10é¡¹


# åˆ›å»ºå…¨å±€å®ä¾‹
pe_report_scorer = PEReportScorer()


# è¡¥å¼ºæ¸…å•æ¨¡æ¿
ENHANCEMENT_CHECKLIST_TEMPLATE = """
# PEçº§è¡Œä¸šç ”æŠ¥è¡¥å¼ºæ¸…å•

## ä»L3åˆ°L4çš„å…³é”®å‡çº§ï¼ˆå·®2-3ä¸ªæ¨¡å—ï¼‰

### âœ… æ¨¡å—1ï¼šæ ‡çš„æ·±æ‹†æ¡ˆä¾‹ï¼ˆå¿…é¡»ï¼‰

**è¦æ±‚**ï¼šé€‰æ‹©1-2ä¸ªé‡ç‚¹å…¬å¸ï¼Œè¿›è¡Œ"æ‹†åˆ°éª¨å¤´é‡Œ"çš„åˆ†æ

**å†…å®¹æ¸…å•**ï¼š
- [ ] æ”¶å…¥ç»“æ„æ‹†è§£ï¼ˆæŒ‰ä¸šåŠ¡æ¿å—ï¼‰
- [ ] AIç›¸å…³æ”¶å…¥å æ¯”
- [ ] æ¯›åˆ©ç‡åˆ†æï¼ˆæŒ‰ä¸šåŠ¡æ¿å—ï¼‰
- [ ] è´¢åŠ¡æŒ‡æ ‡å¯¹æ¯”ï¼ˆè¿‘3å¹´ï¼‰
- [ ] æœé‚¦åˆ†æ
- [ ] ç«äº‰å¯¹æ¯”ï¼ˆé‡åŒ–ï¼‰
- [ ] ä¼°å€¼åˆ†æï¼ˆå†å²åˆ†ä½ï¼‰

**ç¤ºä¾‹æ ¼å¼**ï¼š
```
## æµ·åº·å¨è§†æ·±åº¦åˆ†æ

### æ”¶å…¥ç»“æ„
| ä¸šåŠ¡æ¿å— | æ”¶å…¥(äº¿) | å æ¯” | å¢é€Ÿ | æ¯›åˆ©ç‡ | AIç›¸å…³ |
|----------|----------|------|------|--------|--------|
| å›½å†…ä¸»ä¸š | 520 | 62% | +8% | 44% | 35% |
| æµ·å¤–ä¸»ä¸š | 210 | 25% | +12% | 42% | 30% |
| åˆ›æ–°ä¸šåŠ¡ | 102 | 12% | +28% | 38% | 80% |

AIç›¸å…³æ”¶å…¥åˆè®¡ï¼šçº¦280äº¿ï¼Œå æ¯”29%
```

---

### âœ… æ¨¡å—2ï¼šä¼°å€¼ä¸å›æŠ¥æ¡†æ¶ï¼ˆå¿…é¡»ï¼‰

**è¦æ±‚**ï¼šæä¾›"è´¢åŠ¡æŠ•èµ„è¯­è¨€"ï¼Œä¸åªæ˜¯æˆ˜ç•¥åˆ¤æ–­

**å†…å®¹æ¸…å•**ï¼š
- [ ] ä¼°å€¼é”šç‚¹ï¼ˆè‡³å°‘2ç§æ–¹æ³•ï¼‰
- [ ] å¯æ¯”å…¬å¸ä¼°å€¼å¯¹æ¯”
- [ ] å›æŠ¥æƒ…æ™¯åˆ†æï¼ˆä¹è§‚/ä¸­æ€§/æ‚²è§‚ï¼‰
- [ ] IRR/MOICè®¡ç®—
- [ ] èµ”ç‡åˆ¤æ–­ï¼ˆä¸Šè¡Œç©ºé—´ vs ä¸‹è¡Œé£é™©ï¼‰
- [ ] æŠ•èµ„è€…é€‚é…å»ºè®®

**ç¤ºä¾‹æ ¼å¼**ï¼š
```
## ä¼°å€¼ä¸å›æŠ¥åˆ†æ

### ä¼°å€¼é”šç‚¹
| æ–¹æ³• | å€æ•° | åŸºç¡€æŒ‡æ ‡ | éšå«ä¼°å€¼ |
|------|------|----------|----------|
| PEä¼°å€¼ | 22x | å‡€åˆ©æ¶¦150äº¿ | 3300äº¿ |
| PSä¼°å€¼ | 3.5x | è¥æ”¶950äº¿ | 3325äº¿ |

### å›æŠ¥æƒ…æ™¯
| æƒ…æ™¯ | æ¦‚ç‡ | é€€å‡ºä¼°å€¼ | IRR | MOIC |
|------|------|----------|-----|------|
| ä¹è§‚ | 25% | 5000äº¿ | 35% | 2.5x |
| ä¸­æ€§ | 50% | 4000äº¿ | 25% | 2.0x |
| æ‚²è§‚ | 25% | 2500äº¿ | 10% | 1.3x |

æœŸæœ›IRRï¼š23%ï¼ŒæœŸæœ›MOICï¼š1.9x
```

---

### âœ… æ¨¡å—3ï¼šåå…±è¯†åˆ¤æ–­ï¼ˆå¿…é¡»ï¼‰

**è¦æ±‚**ï¼šå±•ç°"æœ‰ç«‹åœºçš„æŠ•èµ„äºº"è§†è§’

**å†…å®¹æ¸…å•**ï¼š
- [ ] æ˜ç¡®å¸‚åœºå…±è¯†
- [ ] æå‡ºæˆ‘ä»¬çš„ä¸åŒåˆ¤æ–­
- [ ] ç»™å‡ºè®ºè¯é€»è¾‘
- [ ] æ‰¿è®¤é”™è¯¯é£é™©
- [ ] è¯´æ˜æŠ•èµ„å«ä¹‰

**ç¤ºä¾‹æ ¼å¼**ï¼š
```
## åå…±è¯†è§‚ç‚¹

### è§‚ç‚¹1ï¼šä¸­æ¸¸å¹³å°ä»·å€¼å¯èƒ½è¢«é«˜ä¼°

**å¸‚åœºå…±è¯†**ï¼š
> AIä¸­æ¸¸å¹³å°å…·æœ‰é«˜ä»·å€¼ï¼Œå€¼å¾—é«˜ä¼°å€¼

**æˆ‘ä»¬çš„è§‚ç‚¹**ï¼š
> å¤§æ¨¡å‹å´›èµ·å°†å‹ç¼©ä¸­æ¸¸å¹³å°ä»·å€¼ï¼Œä¸­æ¸¸å¯èƒ½æˆä¸º"å¤¹å¿ƒå±‚"

**è®ºè¯**ï¼š
1. å¤§æ¨¡å‹å…·å¤‡ç«¯åˆ°ç«¯èƒ½åŠ›ï¼Œç»•è¿‡ä¸­æ¸¸
   - GPT-4ç­‰å¯ç›´æ¥å®ŒæˆåŸæœ¬éœ€è¦ä¸­æ¸¸å¹³å°çš„ä»»åŠ¡
   - æ•°æ®ï¼šå¤§æ¨¡å‹APIè°ƒç”¨é‡åŒæ¯”å¢é•¿300%

2. ä¸Šä¸‹æ¸¸æŒ¤å‹ä¸­æ¸¸åˆ©æ¶¦ç©ºé—´
   - ä¸Šæ¸¸ç®—åŠ›æˆæœ¬å±…é«˜ä¸ä¸‹
   - ä¸‹æ¸¸å®¢æˆ·è®®ä»·èƒ½åŠ›å¢å¼º

**å¦‚æœæˆ‘ä»¬é”™äº†**ï¼š
- å¤§æ¨¡å‹è½åœ°ä¸åŠé¢„æœŸ
- å‚ç›´é¢†åŸŸknow-howä»éœ€ä¸­æ¸¸æ‰¿è½½

**æŠ•èµ„å«ä¹‰**ï¼š
- è°¨æ…æŠ•èµ„çº¯ä¸­æ¸¸å¹³å°å…¬å¸
- å…³æ³¨æœ‰ä¸Šä¸‹æ¸¸å»¶ä¼¸èƒ½åŠ›çš„å…¬å¸
```

---

## å¿«é€Ÿæå‡æ¸…å•

| ä¼˜å…ˆçº§ | è¡¥å¼ºé¡¹ | é¢„æœŸæå‡ | å·¥ä½œé‡ |
|--------|--------|----------|--------|
| ğŸ”´ é«˜ | æ·»åŠ 1ä¸ªæ ‡çš„æ·±æ‹† | +8åˆ† | 2å°æ—¶ |
| ğŸ”´ é«˜ | æ·»åŠ ä¼°å€¼æ¡†æ¶ | +6åˆ† | 1å°æ—¶ |
| ğŸ”´ é«˜ | æ·»åŠ 1ä¸ªåå…±è¯†è§‚ç‚¹ | +5åˆ† | 1å°æ—¶ |
| ğŸŸ¡ ä¸­ | æ•°æ®æ¥æºæ ‡æ³¨ | +3åˆ† | 30åˆ†é’Ÿ |
| ğŸŸ¡ ä¸­ | å¾®è§‚é£é™©é‡åŒ– | +3åˆ† | 30åˆ†é’Ÿ |
| ğŸŸ¢ ä½ | ç›‘æ§KPI | +2åˆ† | 20åˆ†é’Ÿ |

**é¢„è®¡æ€»æå‡**ï¼š15-20åˆ†ï¼ˆä»L3ç¨³å®šè¿›å…¥L4ï¼‰
"""


def get_enhancement_checklist() -> str:
    """è·å–è¡¥å¼ºæ¸…å•"""
    return ENHANCEMENT_CHECKLIST_TEMPLATE
